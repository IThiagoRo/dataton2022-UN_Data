{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**RETO DATATON BANCOLOMBIA**\n",
        "\n",
        "**GRUPO:** UN_Data\n",
        "\n",
        "**INTEGRANTES:**\n",
        "\n",
        "*   Jhon Daniel Hoyos Arias.\n",
        "*   Ivan Santiago Rojas Martinez.\n",
        "*   Yised Katerine Naranjo García."
      ],
      "metadata": {
        "id": "eQgIf_5XBBRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Avance**\n"
      ],
      "metadata": {
        "id": "ptr_HCJS9Toa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Metodología**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gZe14La5oO7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   La metodologia utilizada para el clasificador de noticias fue  a partir de ***Embeddings pre entrenados de palabras (word2vec)*** Para la creación de un diccionario representativo de cada categoría de interés, que luego fue utilizado para determinar las frecuencias de ocurrencia de las mismas, para clasificar.\n",
        "\n",
        "2.   La metodología utilizada para definir la participación del cliente o el sector en la noticia, fue a partir de las frecuencias del nombre o el sector en el texto, título y url de las noticias.\n",
        "\n",
        "\n",
        "***¿Que son embeddings pre entrenados?***\n",
        "\n",
        "se define como vectores de palabras (word2vec), y a estos se les llama embedding de palabras.\n",
        "Word2Vec es un algoritmo con el cual podemos usar un vector para representar correctamente las palabras de una manera que captura las relaciones semánticas o de significado. Por ejemplo, al analizar estos vectores podemos saber si las palabras son similares u opuestas (analizando la dirección y el sentido del vector). Estos vectores representan el coseno del ángulo entre la diferencia de similitud dada entre 1 y -1 para un par de palabras.\n",
        "\n",
        "Word2Vec es, además, un algoritmo que podemos utilizar para representar correctamente las palabras de manera que se capturara las relaciones semánticas o de significado, esto es importante, porque El uso de la semántica distribucional para entrenar modelos de lenguaje tiene una gran ventaja sobre la mayoría de los otros modelos de aprendizaje automático. Esa ventaja es que podemos entrenarlos con un texto corriente, que tenemos en abundancia, ya que la información que necesitamos es la frecuencia con las que las palabras suelen aparecer juntas.\n",
        "\n",
        "***¿Por qué esta metodología ?***\n",
        "\n",
        "Cuando hablamos de embeddings pre entrenados, hacemos referencia a un conjunto de vectores de números que representan el grado de asociación entre palabras que han sido evaluadas y ejecutadas en un gran número de textos. Gracias a la semántica que word2vec ofrece, para la clasificación de nuestras noticias utilizaremos un modelo de embeddings pre entrenados, de modo que crearemos un vocabulario único y con un alto grado de precisión para nuestras palabras clave, que representan nuestras categorías de clasificación."
      ],
      "metadata": {
        "id": "lqj_qh0i9SDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **librerias utilizadas**"
      ],
      "metadata": {
        "id": "eGbwiNhPo7E1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKm6VbzgRhSu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "import re\n",
        "import collections\n",
        "from collections import Counter, OrderedDict\n",
        "from torchtext.vocab import vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Estrategias**\n",
        "\n",
        "Tomamos un conjunto de 500.000 palabras embedding para entrenar nuestras noticias y de esta manera obtener un diccionario representativo de palabras asociadas a las categorías de interés para el banco, lo interesante es que nuestro modelo asocia la semántica del texto para calcular el nivel de asociación de cada categoría a cada palabra por lo que es bastante informativo.\n",
        "\n",
        "Para definir si la participación del cliente o el sector era significativa dentro de la noticia no se utilizó una metodología muy diferente a la propuesta, le apostamos a una mejor depuración de las palabras.\n"
      ],
      "metadata": {
        "id": "lqb5x6seBR4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  **stoppers**\n",
        "\n",
        "\n",
        "Uno de los limitantes principales es que desde la recolección de las noticias no se consideró la acentuación de las palabras, por lo que nuestro modelo pre entrenado pierde mucha calidad de asociación, sin embargo, pudimos corregir de cierta manera el impacto que esto tenía sobre nuestras categorías de clasificación, asociando el acento a ciertas palabras.\n",
        " \n",
        "Otra situación importante de consideración, es el tema de la participación del cliente o el sector en la noticia, no quedamos muy a gusto con la clasificación presentada, por lo que se continúa trabajando en una mejora mucho más óptima y precisa donde se considere las relaciones semánticas. \n"
      ],
      "metadata": {
        "id": "IhQD-PoIBSAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  **Resultados**\n",
        "\n",
        "Se logró crear un clasificador de noticias y su respectiva participación, a partir de las frecuencias de aparición de las palabras asociadas a su respectiva categoría. "
      ],
      "metadata": {
        "id": "JKs6B5LxBSFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CARGANDO LAS BASES DE DATOS**\n",
        "\n",
        "Se cargan las tres bases de datos para la creación del sistema de recomendación de noticias con el fin de ofrecer a los clientes corporativo del banco información importante y confiable respecto a los sectores en lo que estos se encuentran."
      ],
      "metadata": {
        "id": "vfTdEiRAA_iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "metadata": {
        "id": "TBtSpdsDBNDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_clients = pd.read_csv(\"/content/drive/Shareddrives/Dataton_Bancolombia2022/Data /clientes.csv\")\n",
        "db_news = pd.read_csv(\"/content/drive/Shareddrives/Dataton_Bancolombia2022/Data /noticias.csv\")\n",
        "db_clients_news = pd.read_csv(\"/content/drive/Shareddrives/Dataton_Bancolombia2022/Data /clientes_noticias.csv\")"
      ],
      "metadata": {
        "id": "3AISWpwIswnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DEPURACIÓN GENERAL**"
      ],
      "metadata": {
        "id": "QsLxV4mFBmUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_clients[\"desc_ciiu_division\"] = db_clients[\"desc_ciiu_division\"].apply(lambda x: re.sub(r'[^\\w\\s]', \"\",x.lower()))\n",
        "db_clients[\"desc_ciiuu_clase\"] = db_clients[\"desc_ciiuu_clase\"].apply(lambda x: re.sub(r'[^\\w\\s]', \"\",x.lower()))\n",
        "db_clients[\"desc_ciuu_grupo\"] = db_clients[\"desc_ciuu_grupo\"].apply(lambda x: re.sub(r'[^\\w\\s]', \"\",x.lower()))\n",
        "db_clients[\"subsec\"] = db_clients[\"subsec\"].apply(lambda x: re.sub(r'[^\\w\\s]', \"\",x.lower()))"
      ],
      "metadata": {
        "id": "pcLm_VPjBgQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_news[\"news_title\"] = db_news[\"news_title\"].apply(lambda x: re.sub(r'[^\\w\\s]', \"\",x.lower()))\n",
        "db_news[\"news_text_content\"] = db_news[\"news_text_content\"].apply(lambda x: re.sub(r'[^\\w\\s]', \"\",x.lower()))\n"
      ],
      "metadata": {
        "id": "WmYmoDjrBtEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_clients_news.head()"
      ],
      "metadata": {
        "id": "bcOfKb11ns-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6702a761-713c-4a87-ebb1-0b3980a408b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         nit    news_id                                  news_url_absolute  \\\n",
              "0  900378212  news10006  https://www.bluradio.com/economia/precio-dolar...   \n",
              "1  900378212  news10011  https://www.semana.com/economia/macroeconomia/...   \n",
              "2  860034313  news10011  https://www.semana.com/economia/macroeconomia/...   \n",
              "3  900378212  news10015  https://elcomercio.pe/respuestas/que/gustavo-p...   \n",
              "4  900166896  news10015  https://elcomercio.pe/respuestas/que/gustavo-p...   \n",
              "\n",
              "  news_init_date news_final_date  \n",
              "0     2022-07-30      2022-08-14  \n",
              "1     2022-07-30      2022-08-14  \n",
              "2     2022-07-30      2022-08-14  \n",
              "3     2022-07-30      2022-08-14  \n",
              "4     2022-07-30      2022-08-14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aca440af-a38d-4d03-8bb6-83f07912ae9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nit</th>\n",
              "      <th>news_id</th>\n",
              "      <th>news_url_absolute</th>\n",
              "      <th>news_init_date</th>\n",
              "      <th>news_final_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>900378212</td>\n",
              "      <td>news10006</td>\n",
              "      <td>https://www.bluradio.com/economia/precio-dolar...</td>\n",
              "      <td>2022-07-30</td>\n",
              "      <td>2022-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>900378212</td>\n",
              "      <td>news10011</td>\n",
              "      <td>https://www.semana.com/economia/macroeconomia/...</td>\n",
              "      <td>2022-07-30</td>\n",
              "      <td>2022-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>860034313</td>\n",
              "      <td>news10011</td>\n",
              "      <td>https://www.semana.com/economia/macroeconomia/...</td>\n",
              "      <td>2022-07-30</td>\n",
              "      <td>2022-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>900378212</td>\n",
              "      <td>news10015</td>\n",
              "      <td>https://elcomercio.pe/respuestas/que/gustavo-p...</td>\n",
              "      <td>2022-07-30</td>\n",
              "      <td>2022-08-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>900166896</td>\n",
              "      <td>news10015</td>\n",
              "      <td>https://elcomercio.pe/respuestas/que/gustavo-p...</td>\n",
              "      <td>2022-07-30</td>\n",
              "      <td>2022-08-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aca440af-a38d-4d03-8bb6-83f07912ae9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aca440af-a38d-4d03-8bb6-83f07912ae9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aca440af-a38d-4d03-8bb6-83f07912ae9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LIMPIEZA DE DATOS Y TOKENIZACIÓN**\n",
        "\n",
        "Se realiza una limpieza de texto, en la base de datos, con el fin de eliminar todo aquello no este sumando información o patrones importantes para el análisis, mediante la función $limpiar tokenizar^1$  limpiando paso a paso y luego procediendo a una tokenización representando el texto como una lista de palabras. En ese sentido, dado que lo que interesa es realizar una buena categorización de noticias, se procede a eliminar:\n",
        "\n",
        "\n",
        "*   Signos de puntuación.\n",
        "*   Eliminación de patrones no informativos como páginas web (http)\n",
        "* Eliminicación de números\n",
        "* Eliminación de espacio en blanco adicionales\n",
        "* Conversión del texto a minúsculas, para estandarización de las palabras)\n",
        "* Eliminación de tokens con una longitud menor a 2, para encargarse de palabras que no son de mucha relevancia para el análisis como: \"y\", \"o\", entre otras. \n",
        "\n"
      ],
      "metadata": {
        "id": "A_RAwQlzdeUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def clean_tokenizer_news(texto):\n",
        "\n",
        "    nuevo_texto = texto.lower()\n",
        "    # Eliminación de páginas web (palabras que empiezan por \"http\")\n",
        "    nuevo_texto = re.sub('http\\S+', ' ', nuevo_texto)\n",
        "    # Eliminación de signos de puntuación\n",
        "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
        "    nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
        "    # Eliminación de números\n",
        "    nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
        "    # Eliminación de espacios en blanco múltiples\n",
        "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
        "    # Tokenización por palabras individuales\n",
        "    nuevo_texto = nuevo_texto.split(sep = ' ')\n",
        "    # Eliminación de tokens con una longitud < 2\n",
        "    nuevo_texto = [token for token in nuevo_texto if len(token) > 2]\n",
        "    \n",
        "    return(nuevo_texto)\n",
        "    "
      ],
      "metadata": {
        "id": "qF5GLy-WdbPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def clean_tokenizer_url(texto):\n",
        "    nuevo_texto = texto.lower()\n",
        "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
        "    nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
        "    nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
        "    nuevo_texto = re.sub(\"https?\", ' ', nuevo_texto)\n",
        "    nuevo_texto = re.sub(\"www?\", ' ', nuevo_texto)\n",
        "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
        "    nuevo_texto = nuevo_texto.split(sep = '-')\n",
        "    nuevo_texto = [token for token in nuevo_texto if len(token) >2] \n",
        "    return(nuevo_texto)"
      ],
      "metadata": {
        "id": "LZvVWIw7Mw9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textUrl=[]\n",
        "for i in range(0, db_news.shape[0]):\n",
        "  textUrl.append(clean_tokenizer_url(db_news.news_url_absolute[i]))\n",
        "\n",
        "textTitle=[]\n",
        "for i in range(1, db_news.shape[0]):\n",
        "  textTitle.append(clean_tokenizer_news(db_news.news_title[i]))\n",
        "\n",
        "textNews=[]\n",
        "for i in range(1, db_news.shape[0]):\n",
        "  textNews.append(clean_tokenizer_news(db_news.news_text_content[i]))\n"
      ],
      "metadata": {
        "id": "zaUP0QukdqKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACENTUACIÓN DE LAS PALABRAS CLAVES**\n",
        "Se decidió hacer la acentuación de palabras claves dentro de nuestro modelo, dado que los embeddings pre entrenados funcionan mejor con palabras acentuadas, de esta manera se soluciona un poco el efecto de no considerar los acentos, y se logra una mejor precisión en el ajuste de los sentimientos de nuestras palabras.  \n"
      ],
      "metadata": {
        "id": "Tta90AkcFpWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for title in textTitle:\n",
        "    for i in range(len(title)):\n",
        "        if title[i] == \"macroeconomia\":\n",
        "            title[i] = \"macroeconomía\"\n",
        "        \n",
        "        if title[i] == \"reputacion\":\n",
        "           title[i] = \"reputación\"\n",
        "\n",
        "        if title[i] == \"innovacion\":\n",
        "           title[i] = \"innovación\"\n",
        "\n",
        "        if title[i] == \"economía\":\n",
        "           title[i] = \"economía\"\n",
        "                    \n",
        "        \n",
        "for new in textNews:\n",
        "    for i in range(len(new)):\n",
        "        if new[i] == \"macroeconomia\":\n",
        "           new[i] = \"macroeconomía\"\n",
        "        \n",
        "        if new[i] == \"reputacion\":\n",
        "           new[i] = \"reputación\"\n",
        "        \n",
        "        if new[i] == \"innovacion\":\n",
        "           new[i] = \"innovación\"\n",
        "\n",
        "        if new[i] == \"economía\":\n",
        "           new[i] = \"economía\"\n",
        "\n",
        "for url in textUrl:\n",
        "    for i in range(len(url)):\n",
        "        if url[i] == \"macroeconomia\":\n",
        "           url[i] = \"macroeconomía\"\n",
        "\n",
        "        if url[i] == \"reputacion\":\n",
        "           url[i] = \"reputación\"\n",
        "        \n",
        "        if url[i] == \"innovacion\":\n",
        "           url[i] = \"innovación\"\n",
        "\n",
        "        if url[i] == \"economía\":\n",
        "           url[i] = \"economía\"\n"
      ],
      "metadata": {
        "id": "nTPDme7Qf0rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELO PRE-ENTRENADO**\n",
        "\n",
        "\n",
        "Para la categorización de las noticias, inicialmente se hace uso de un modelo Enbedding-s pre-entrenado, ya que este permite la representación de texto, mediante la incorporación de algoritmos con Wordvec2 y métodos de entrenamiento aproximados. Este modelo nos permite en nuestro análisis que mediante esta incrustación de palabras con un enfoque que permita capture algo acerca del significado de las palabras y lograr con esto una mejor clasificación de las noticias. Estas incrustaciones de palabras funcionan utilizando el algoritmo wordvec2 para entrenar un conjunto de vectores densos y continuos de longitud fija basados en un gran corpus de texto, en donde aprender una palabra incrustada a partir de un texto implica cargar y organizar el texto en frases y proporcionarlas al constructor de una nueva instancia, cada frase debe ser simbólica para que pueda categorizarse adecuadamente.\n",
        " \n",
        "• El siguiente código descarga un archivo que contiene 1.000.653 incrustaciones de palabras con una dimensión de 300 entrenadas, estas Enbeddings de palabras se entrenaron con un algoritmo modelo skip-gram con muestreo negativo, con una frecuencia mínima de 5 palabras y además las 273 palabras más comunes sé re-muestrearon. Luego de esto se obtiene con este modelo un total de, 771508817 palabras sin procesar y un total de 1000653 tokens únicos para la categorización.\n"
      ],
      "metadata": {
        "id": "y16t0mmsi6o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2\n",
        "!bzip2 -d SBW-vectors-300-min5.txt.bz2"
      ],
      "metadata": {
        "id": "_ZcaAVl9mrP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2644de-c754-420f-a659-1023e3b68431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 00:09:00--  https://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2\n",
            "Resolving cs.famaf.unc.edu.ar (cs.famaf.unc.edu.ar)... 200.16.17.55\n",
            "Connecting to cs.famaf.unc.edu.ar (cs.famaf.unc.edu.ar)|200.16.17.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 818175453 (780M) [application/x-bzip2]\n",
            "Saving to: ‘SBW-vectors-300-min5.txt.bz2’\n",
            "\n",
            "SBW-vectors-300-min 100%[===================>] 780.27M  18.4MB/s    in 44s     \n",
            "\n",
            "2022-11-01 00:09:45 (17.9 MB/s) - ‘SBW-vectors-300-min5.txt.bz2’ saved [818175453/818175453]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CANTIDAD DE EMBEDDING Y DIMENSIÓN**\n",
        "\n",
        "Se observa la cantidad de cada Embedding y la dimensión de cada uno de ellos. Luego, cada línea contiene el token vectorizado y luego el vector propiamente dicho.\n"
      ],
      "metadata": {
        "id": "ApGhwWiZGayJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open( \"SBW-vectors-300-min5.txt\", 'r') as f:\n",
        "  n_lin = 0\n",
        "  for line in f:\n",
        "    print(line)\n",
        "    n_lin += 1\n",
        "    if n_lin>3: break"
      ],
      "metadata": {
        "id": "lEXz_hkBlCui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619211a4-f4f4-4f7f-c621-6a3c190820ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000653 300\n",
            "\n",
            "de -0.029648 0.011336 0.019949 -0.088832 -0.025225 0.056844 0.025473 0.014068 0.163694 -0.067154 0.014738 0.027134 0.066443 -0.044846 -0.044987 -0.040898 0.030311 0.034196 -0.049240 0.008537 -0.068091 -0.087938 0.035300 0.149385 -0.012350 0.012613 0.029350 0.069596 0.039111 0.057652 0.069954 -0.066217 -0.041784 0.028623 0.026772 -0.066392 0.002953 -0.012188 -0.030363 0.040222 0.034858 0.027469 -0.029034 -0.048748 -0.038582 -0.051553 -0.033501 -0.019008 0.003043 0.110712 -0.025096 0.111082 0.035244 0.114207 0.010195 0.051511 -0.040649 -0.113944 0.044873 0.052011 0.067360 0.049054 -0.127085 -0.031846 0.032848 0.040825 -0.084873 0.059801 -0.067424 0.016531 -0.084565 0.057024 0.083288 -0.010136 -0.048508 0.051757 0.046664 0.018102 -0.052320 -0.000765 0.053662 -0.009967 0.082858 0.009068 0.054575 -0.003466 -0.023376 0.023069 0.088513 0.018504 -0.039503 -0.032980 -0.002139 0.000010 -0.107627 0.007699 0.046351 -0.003062 0.030500 0.113650 0.032536 -0.097301 -0.013734 0.098345 0.080898 -0.064173 -0.008874 -0.144751 0.037585 0.013290 0.059674 0.006163 0.007318 0.000053 -0.060292 -0.059135 0.049497 -0.011438 -0.095108 -0.043465 0.048567 -0.043990 -0.030774 0.005092 -0.032265 0.009392 0.018503 0.084857 0.109709 -0.020662 0.017696 0.026699 -0.076638 -0.014106 -0.035155 0.046999 -0.003727 -0.047805 0.044270 0.011314 0.036524 -0.069505 -0.014850 -0.003538 -0.047049 0.029349 0.034521 -0.032199 0.116497 -0.077610 0.068234 -0.016126 -0.066454 -0.079914 -0.020723 -0.064905 0.069560 0.021368 -0.049497 -0.046599 0.067663 -0.069035 0.118015 0.027463 -0.006176 -0.034514 -0.026515 0.040308 0.091113 -0.080539 0.132408 -0.070958 0.019730 0.033399 0.003489 -0.159659 -0.004230 0.004888 -0.056615 0.061021 0.025117 0.099613 0.063876 -0.006202 -0.049316 -0.020530 0.008522 -0.094168 -0.009451 -0.034682 -0.026801 0.065383 0.042528 -0.013688 0.035068 0.119803 -0.020278 0.111882 -0.068336 0.050245 -0.123240 0.002248 0.010229 -0.062540 -0.017837 -0.115210 0.051036 0.026920 0.083457 0.062902 0.003083 -0.037112 -0.015425 0.001716 0.018002 0.101100 0.019446 0.074839 0.059951 0.072243 -0.025459 -0.039853 0.077950 0.060199 -0.070603 0.060652 0.023855 -0.035858 -0.058043 -0.075130 0.000670 0.082828 -0.013141 0.144692 -0.105775 0.087624 0.047030 -0.015700 -0.042360 0.026337 0.144966 0.021922 0.012097 -0.011443 -0.110208 0.009333 -0.081423 -0.027137 0.000827 0.085389 0.034464 0.032338 -0.015040 0.009954 -0.011759 -0.042395 -0.000467 0.055047 -0.049710 -0.104978 0.031742 0.037020 -0.007016 -0.049712 0.041684 0.018348 -0.001201 0.019282 0.005763 0.074952 -0.018588 0.016055 0.119526 -0.014613 0.020598 0.027312 0.024252 -0.024044 -0.026332 -0.063152 -0.095363 -0.034335 -0.062552 -0.035730 0.091165 0.009686 0.020341 -0.012004 0.011826 -0.084301 0.011144 0.074969 -0.004862 -0.014076 0.025692 -0.077322 -0.022998 -0.128057 -0.004917 0.062628\n",
            "\n",
            "DIGITO -0.013002 -0.000781 0.032629 -0.088482 0.021298 0.039986 0.068380 0.006264 0.091135 0.000434 0.009331 0.028423 0.020692 -0.013583 -0.032420 0.024689 0.033696 -0.023145 -0.035633 -0.010274 -0.081628 -0.053617 0.051587 0.091048 -0.016919 0.033980 0.073040 0.100553 0.027454 0.053528 -0.013338 -0.055065 -0.045165 0.053637 0.017824 -0.010603 0.013005 -0.002873 -0.069372 0.008059 -0.001416 0.012431 -0.080941 -0.065539 0.007878 -0.021076 -0.035602 -0.049555 0.048422 0.104744 -0.054366 0.018188 0.031350 0.098584 0.094406 0.019084 -0.033111 -0.092422 0.058111 0.042169 0.009418 0.052326 -0.076443 -0.065708 0.039609 0.070779 -0.104470 0.016466 -0.100397 -0.012615 -0.062208 0.044405 0.040897 0.047476 -0.010739 0.005267 0.081850 0.034962 -0.094599 0.015806 0.040549 -0.003756 0.036048 0.022974 0.035902 0.023096 0.039259 -0.016199 0.043539 0.014725 -0.006119 -0.018587 -0.014097 -0.002395 -0.134557 0.041796 0.001652 0.058954 0.078891 0.114630 0.105141 -0.128402 -0.066549 0.079760 0.024396 -0.113124 -0.001198 -0.135299 0.037189 -0.035586 0.094150 0.018785 -0.005085 -0.018881 -0.115887 -0.082005 0.024251 -0.033302 -0.078087 -0.022660 0.007569 -0.096935 -0.023436 -0.023365 -0.026818 -0.023903 0.046716 0.047488 0.067228 -0.033471 0.038515 0.023762 -0.125687 0.042650 -0.000855 0.001957 -0.052234 -0.066039 0.082063 0.001344 -0.009984 -0.117670 -0.004480 -0.006035 -0.006549 0.032035 -0.021916 -0.028900 0.087054 -0.103109 0.033930 -0.036428 0.002393 -0.009741 -0.069586 -0.020493 0.001128 -0.067282 -0.043965 -0.075068 0.099662 -0.017608 0.066231 -0.015208 0.031142 -0.027223 -0.033040 0.053951 0.046496 -0.131409 0.131169 -0.007959 -0.011152 0.000514 -0.028036 -0.168291 -0.022996 -0.032068 -0.039740 0.016381 0.005333 0.099232 0.051381 -0.000236 -0.073249 0.012495 -0.015802 -0.091128 -0.003723 -0.022181 -0.046669 0.059063 0.064704 0.028548 0.011399 0.117871 -0.028101 0.068917 0.008404 0.030469 -0.104959 0.002380 -0.040827 0.041906 -0.024125 -0.046123 0.006722 0.074472 0.107256 0.066871 -0.017771 -0.007295 -0.007886 -0.031781 0.050508 0.043651 -0.043853 0.119111 0.048094 0.027306 -0.012738 -0.055844 0.000362 0.073290 -0.094030 0.088980 0.033241 -0.082521 -0.114527 -0.077395 -0.057670 0.046407 0.032855 0.090644 -0.084556 0.130570 0.046755 -0.000518 -0.062754 0.003713 0.142896 -0.000069 0.012594 -0.018961 -0.071201 -0.050190 -0.107127 -0.011871 0.030770 0.038137 0.023721 0.028529 0.065621 0.018548 0.044810 -0.023708 0.028006 0.028420 0.000359 -0.051305 0.035992 0.077839 -0.046144 -0.010108 0.056583 0.040588 0.106301 0.046546 -0.028884 0.031776 -0.023081 0.011159 0.058000 -0.002292 -0.021265 0.030547 -0.046024 0.021797 0.090825 -0.097326 -0.077190 0.060535 -0.078626 -0.108777 0.048595 -0.039361 0.022155 -0.015696 0.007409 -0.130169 0.048188 0.095554 -0.007935 -0.010960 0.009057 -0.055717 -0.016302 -0.132496 0.029352 0.063434\n",
            "\n",
            "la -0.022313 0.022251 0.036704 -0.096540 -0.052861 0.024058 0.011043 0.002622 0.156215 -0.042965 0.039763 -0.003066 0.038801 -0.053368 -0.041667 -0.030635 -0.007328 0.003714 -0.114164 -0.025042 -0.051972 -0.055420 0.042268 0.105376 -0.060363 -0.019926 -0.001696 0.102281 0.040454 0.088647 0.088293 -0.019142 0.003859 -0.027580 0.018365 -0.088503 -0.011589 -0.052447 -0.008289 -0.020715 0.009673 0.012709 -0.082492 -0.040010 -0.057307 -0.087804 -0.020654 0.018062 0.034962 0.131913 -0.033211 0.130602 0.014101 0.057181 0.005193 0.058847 -0.062297 -0.131932 0.017364 0.088293 0.053714 0.019530 -0.121452 0.018164 0.060706 0.088240 -0.059637 0.037769 -0.052032 0.079613 -0.133862 -0.006583 0.068153 0.041149 -0.059254 0.057758 0.010501 0.058813 -0.026589 -0.078938 0.032387 -0.010713 0.054048 0.016489 0.052541 0.019058 -0.035579 0.035734 0.079074 0.027151 -0.034716 -0.041740 0.027742 0.038502 -0.131790 0.000054 0.023742 -0.015529 -0.016263 0.074132 -0.034666 -0.074852 0.005035 0.113395 0.032837 0.004166 0.004269 -0.135889 0.062360 0.051681 0.044063 0.054768 0.067986 0.032836 -0.095447 -0.072281 0.028622 0.029793 -0.057763 -0.034192 0.001806 -0.043905 -0.044698 0.007713 -0.047600 0.014539 -0.004542 0.047801 0.049999 -0.044603 0.038886 0.022660 -0.053500 -0.062190 -0.085413 0.072058 0.029248 -0.031418 -0.055516 0.025744 0.060207 -0.014266 -0.022034 0.018754 -0.015960 -0.001577 0.020190 -0.069271 0.138597 -0.101960 0.043598 0.005266 -0.075013 -0.063113 0.049575 -0.053393 0.043651 0.012303 -0.034139 0.024200 0.055642 -0.030245 0.100529 -0.017504 -0.060918 -0.100398 -0.043245 0.047509 0.040789 -0.048056 0.107280 -0.079895 0.049304 0.028526 0.040193 -0.097320 -0.000557 0.004501 -0.000329 0.006951 0.037162 0.053592 0.071350 0.025196 -0.031765 -0.000354 -0.013615 -0.080432 0.026182 -0.030302 -0.028832 -0.002504 0.071907 -0.027518 0.008791 0.142758 0.008447 0.099430 -0.051668 0.107455 -0.098141 -0.060972 -0.013618 -0.041751 0.039856 -0.068698 0.027978 -0.026681 0.034578 0.036537 -0.019795 0.007946 0.014677 -0.028922 0.026407 0.100824 0.024597 0.057108 0.026002 0.004507 0.008445 -0.070869 0.119097 0.036694 0.017460 0.024830 0.049018 -0.042634 -0.075510 -0.044751 0.038456 0.074046 -0.046579 0.143879 -0.062126 0.027630 0.072420 -0.044438 -0.066515 0.036794 0.196606 0.001752 0.048581 0.016231 -0.133789 0.010679 -0.072775 -0.007094 -0.010939 0.084204 0.018636 0.107546 -0.044642 0.017310 -0.013498 0.008038 0.006861 0.067795 -0.064582 -0.110481 0.034113 0.054558 -0.020856 -0.100647 0.049993 0.001914 -0.059515 0.010465 0.000765 0.135641 -0.019326 0.037263 0.065312 0.008730 0.007405 0.044418 0.038109 -0.022185 -0.045651 -0.064789 -0.119470 0.002855 -0.037815 -0.011621 0.034758 0.026737 0.077853 -0.000177 -0.009866 -0.037531 0.018481 0.067658 0.005637 -0.034123 0.003338 -0.062329 -0.016266 -0.087151 -0.020682 0.033452\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CARGANDO EL CONTENIDO EN LA MEMORIA**\n",
        "\n",
        "Se generá una clase que permite almacenar los enbeddings en la memoria para poder acceder a ellos de manera más ordenada.\n",
        "\n",
        "Esta clase contendrá varios atributos útiles:\n",
        "\n",
        "*   idx_to_token: es una lista que contendrá los tokens. \n",
        "*   idx_to_vec: es una lista que contendrá los embeddings. \n",
        "*   dim: es la dimensión de los embeddings.\n",
        "*   token_to_idx: devuelve el id correspondiente al token pasado como parámetro."
      ],
      "metadata": {
        "id": "NhSc7-N7GvvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class TokenEmbedding:\n",
        "  \"\"\"Token Embedding.\"\"\"\n",
        "  def __init__(self, file_name, n):\n",
        "    self.idx_to_token, self.idx_to_vec, self.dim = self._load_embedding(\n",
        "        file_name, n)\n",
        "    self.unknown_idx = 0\n",
        "    self.token_to_idx = {token: idx for idx, token in\n",
        "                          enumerate(self.idx_to_token)}\n",
        "  \n",
        "\n",
        "  def _load_embedding(self, file_name, n):\n",
        "    idx_to_token, idx_to_vec = ['<unk>'], []\n",
        "    with open( file_name, 'r') as f:\n",
        "      first_read = True\n",
        "      i=0\n",
        "      for line in f:\n",
        "        if n<i: break\n",
        "        else: i+=1\n",
        "        if first_read:\n",
        "          first_read = False\n",
        "          continue\n",
        "        elems = line.rstrip().split(' ')\n",
        "        token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
        "        # Skip header information, such as the top row in fastText\n",
        "        if len(elems) > 1:\n",
        "            idx_to_token.append(token)\n",
        "            idx_to_vec.append(elems)\n",
        "    idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
        "    return idx_to_token, torch.tensor(idx_to_vec), len(idx_to_vec[0])\n",
        "\n",
        "  def __getitem__(self, tokens):\n",
        "    indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
        "                for token in tokens]\n",
        "    vecs = self.idx_to_vec[torch.tensor(indices)]\n",
        "    return vecs\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)"
      ],
      "metadata": {
        "id": "-f8ofIzujG6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a cargar los embeddings en un objeto llamado  *spanish_w2v*. Donde se cargaron 500000 tokens"
      ],
      "metadata": {
        "id": "EFFQKMvBHVhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_w2v = TokenEmbedding(\"SBW-vectors-300-min5.txt\",500000)"
      ],
      "metadata": {
        "id": "3q8e6nOIjG9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRUEBA DE DATOS PRE-ENTRENADOS**\n",
        "\n",
        "Se evaluarán lo embeddings usando los vectores del algoritmo *wordvec2* para encontrar palabras similares respecto a cada clasificación de las noticias.\n"
      ],
      "metadata": {
        "id": "PKmd82zUK-8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_economia = spanish_w2v.token_to_idx[\"reputacion\"]\n",
        "spanish_w2v.idx_to_vec[id_economia]"
      ],
      "metadata": {
        "id": "a-IC4RhAjHAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPLEMENTACIÓN DE FUNCIÓN KNN PARA SIMILITUD DE PALABRAS**\n",
        "Se implementa la siguiente función de K vecinos más cercanos KNN, para encontrar palabras similares, usando la similitud de coseno de los vectores de palabras del modelo entrenado."
      ],
      "metadata": {
        "id": "gCGJWOGEKhCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(W, x, k):\n",
        "    cos = torch.mv(W, x.reshape(-1,)) / (\n",
        "        torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\n",
        "        torch.sqrt((x * x).sum()))\n",
        "    _, topk = torch.topk(cos, k=k)\n",
        "    return topk, [cos[int(i)] for i in topk]"
      ],
      "metadata": {
        "id": "Ey6puPZLjHDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el siguiente código se buscan las palabras similares de la clasificación que de sea de las noticias, utilizando las incrustaciones de palabras pre-entrenadas."
      ],
      "metadata": {
        "id": "evEx-n5XK3hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_tokens(query_token, k, embed):\n",
        "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\n",
        "    for i, c in zip(topk[1:], cos[1:]):  # Exclude the input word\n",
        "        print(f'cosine sim={float(c):.3f}: {embed.idx_to_token[int(i)]}')\n",
        "\n",
        "get_similar_tokens('innovación', 100, spanish_w2v)"
      ],
      "metadata": {
        "id": "uXnqhGR-k6Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ENTRENAMIENTO DE NOTICIAS**\n",
        "\n",
        "En este apartado, se ingresan vectores de la palabra tokenizadas referentes al texto de las noticias, y se obtiene un vocabulario (vocab_news) que tiene la misma estructura de los enbedding pre-entrenados, con un tamaño de 65173.\n",
        " \n",
        "Cabe notar que los embeddings pre-entrenados que estamos tomando tienen una capacidad de un millón de palabras, pero solo se toman 500.000 por memoria computacional.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "msN84z0wLLOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_vocab(oraciones,min_freq=1):\n",
        "  #Comprueba que oraciones es una lista de listas\n",
        "  if oraciones and isinstance(oraciones[0], list):\n",
        "    #Transforma una lista anidada en una lista simple \n",
        "    tokens = [token for line in oraciones for token in line]\n",
        "  counter_obj = collections.Counter()\n",
        "  counter_obj.update(tokens)\n",
        "  sorted_by_freq_tuples = sorted(counter_obj.items(), key=lambda x: x[1], reverse=True)\n",
        "  ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "  vocabulario = vocab(ordered_dict, min_freq=min_freq)\n",
        "  return vocabulario, ordered_dict\n",
        "vocab_news, ordered_dict = make_vocab(textNews,5)\n"
      ],
      "metadata": {
        "id": "txRcPwTtqSic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f\"Este vocabulario tiene un tamaño de {len(vocab_news.get_itos())}\""
      ],
      "metadata": {
        "id": "Buub40QPEpIs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f261f72a-d896-4ee8-9f33-d6b157faad0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Este vocabulario tiene un tamaño de 65173'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CANTIDAD DE EMBEDDING Y DIMENSIÓN PARA EL ENTRENAMIENTO DE NOTICIAS**\n",
        "\n"
      ],
      "metadata": {
        "id": "-aPYHQdUpSCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este apartado es utilizado para crear una capa de embeddings, y son almacenados en una matriz, la cual contendrá un vector de números similares a los tensores obtenidos de los embeddings pre entrenados."
      ],
      "metadata": {
        "id": "UTKYavQDIbVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_len = len(vocab_news.get_itos())\n",
        "weights_matrix = np.zeros((len(vocab_news.get_itos()), spanish_w2v.dim))\n",
        "words_found = 0\n",
        "words_not_found = []\n",
        "\n",
        "for i, word in enumerate(vocab_news.get_itos()):\n",
        "    try: \n",
        "        weights_matrix[i] = spanish_w2v[[word]][0]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(spanish_w2v.dim, ))\n",
        "        words_not_found.append(word)\n",
        "\n",
        "weights_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gj3KFNCpY-F",
        "outputId": "cb2c4898-d9a5-4353-e96c-3095a235af13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65173, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREANDO UNA RED NEURONAL**\n",
        "Para esta parte, se hace la transformación de la matriz que contiene los vectores de números asociados, y se transforma a los tensores necesarios para crear los embeddings de nuestras noticias.\n",
        "Por último, se prueba con un modelo de 256 variables ocultas y 2 capas de embeddings con el fin de no sobre ajustar el modelo.\n"
      ],
      "metadata": {
        "id": "E-AQG5tTIrnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch import nn \n",
        "\n",
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': torch.tensor(weights_matrix)})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ],
      "metadata": {
        "id": "o71bncKRnIXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ToyNN(nn.Module):\n",
        "    def __init__(self, weights_matrix, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
        "        \n",
        "    def forward(self, inp, hidden):\n",
        "        return self.gru(self.embedding(inp), hidden)"
      ],
      "metadata": {
        "id": "Uy3dnr_znId-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = ToyNN(weights_matrix,256,2)"
      ],
      "metadata": {
        "id": "iNdJnewrnIhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Validando nuestro modelo**"
      ],
      "metadata": {
        "id": "U-4-rCu_JTkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_tokens2(query_token, k, embed):\n",
        "    W = embed.weight.data\n",
        "    assert vocab_news.__contains__(query_token), \"El token no está en el vocabulario\"\n",
        "    x = W[vocab_news[query_token]]\n",
        "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
        "    cos = torch.mv(W, x) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
        "                                      torch.sum(x * x) + 1e-9)\n",
        "    topk = torch.topk(cos, k=k+1)[1].cpu().numpy().astype('int32')\n",
        "    tokens = vocab_news.get_itos()\n",
        "    arrayText=[]\n",
        "    for i in topk[1:]:  # Remove the input words\n",
        "        #print(f'cosine sim={float(cos[i]):.3f}: {tokens[i]}')\n",
        "        arrayText.append(tokens[i])\n",
        "\n",
        "    return(arrayText)\n"
      ],
      "metadata": {
        "id": "vumewrECd5D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=get_similar_tokens2('macroeconomía', 50, model.embedding)\n",
        "k"
      ],
      "metadata": {
        "id": "Rp4__jRuYPZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREACIÓN DEL DICCIONARIO**\n",
        "\n",
        "Se crea un diccionario para almacenar las palabras con datos claves para la respectiva clasificación de las palabras según las diferentes categorías que se estan teniendo en cuenta para la realización del recomendador de noticias:\n",
        "\n",
        "* Macroeconomía.\n",
        "* Sostenibilidad\n",
        "* Innovación\n",
        "* Regulaciones\n",
        "* Alianzas\n",
        "* Reputación"
      ],
      "metadata": {
        "id": "46VfQkV2LgDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorys = [\"macroeconomía\", \"sostenibilidad\", \"innovación\", \"regulaciones\", \"alianzas\", \"reputación\"]\n",
        "diccionary={}\n",
        "\n",
        "for category in categorys:\n",
        "    k = get_similar_tokens2(category, 50, model.embedding)\n",
        "    diccionary[category] = k\n",
        "\n",
        "\n",
        "print(diccionary)\n"
      ],
      "metadata": {
        "id": "bjMXdn2DnIma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897d14d7-cca5-41f6-a570-8a0cf08ea710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'macroeconomía': ['economistas', 'keynesiana', 'finanzas', 'keynesianismo', 'economista', 'monetaria', 'monetarias', 'ciencias', 'recesiones', 'marginalista', 'financiera', 'inflacionarios', 'contractiva', 'sostenibilidad', 'competitividad', 'gobernanza', 'neoliberales', 'dolarizar', 'coyuntura', 'monetario', 'distributivos', 'coyunturales', 'neurociencia', 'monetarios', 'neoliberal', 'cientistas', 'transformacional', 'agronegocios', 'redistributivas', 'economics', 'inflaciones', 'fiscalidad', 'finanza', 'sustentabilidad', 'neoliberalismo', 'inflacionarias', 'extractivista', 'ambientalismo', 'prospectiva', 'humanidades', 'microfinanzas', 'transdisciplinar', 'coyuntural', 'externalidades', 'especulativa', 'emprendedurismo', 'inflacionario', 'cambiaria', 'bancarizada', 'dolarizada'], 'sostenibilidad': ['sustentabilidad', 'sostenible', 'viabilidad', 'sostenibles', 'competitividad', 'medioambiental', 'sustentable', 'eficiencia', 'ambiental', 'medioambientales', 'bienestar', 'gobernanza', 'sustentables', 'equidad', 'rentabilidad', 'estabilidad', 'medioambiente', 'pertinencia', 'insostenibilidad', 'productividad', 'asequibilidad', 'autosuficiencia', 'reequilibrio', 'integralidad', 'gobernabilidad', 'biodiversidad', 'eficacia', 'accesibilidad', 'extractivista', 'ecoeficiencia', 'saneadas', 'previsibilidad', 'potenciamiento', 'insertarnos', 'propenda', 'propendiendo', 'asociativismo', 'desarrollo', 'fiabilidad', 'inocuidad', 'ecoeficientes', 'saneada', 'condicionalidad', 'socioambientales', 'suficiencia', 'corresponsabilidad', 'multifuncionalidad', 'innovación', 'saneamiento', 'agroecosistemas'], 'innovación': ['competitividad', 'creatividad', 'innovadora', 'empresarial', 'emprendedurismo', 'electromovilidad', 'innovar', 'innovadoras', 'desarrollo', 'excelencia', 'innovaciones', 'innovadores', 'impulsar', 'nanociencia', 'emprendedores', 'potenciamiento', 'productividad', 'agroalimentaria', 'agroindustria', 'innovador', 'emprendedora', 'dinamicen', 'emprendedor', 'agroalimentario', 'extensionismo', 'mipyme', 'ecoeficiente', 'fomento', 'inversiones', 'incentivar', 'estimular', 'megamuestra', 'interdisciplinariedad', 'agroindustrial', 'tecnologicas', 'inventiva', 'agroalimentos', 'startups', 'competitivas', 'fomentar', 'sostenible', 'productivos', 'sustentabilidad', 'ecoeficientes', 'productivo', 'dinamizando', 'empresariales', 'potenciar', 'eficiencia', 'pymes'], 'regulaciones': ['reglamentaciones', 'normas', 'normativas', 'reglamentos', 'estrictas', 'leyes', 'disposiciones', 'restricciones', 'reglas', 'prescripciones', 'regulatorias', 'normativa', 'directivas', 'estrictos', 'vigentes', 'medidas', 'especificaciones', 'rigurosas', 'rigen', 'exigencias', 'regulen', 'reglamentar', 'reglamentarias', 'legislaciones', 'salvaguardas', 'reglamentan', 'promulgadas', 'regulan', 'impositivas', 'limitaciones', 'reglamento', 'prohibiciones', 'estipulaciones', 'flexibilizan', 'regulatorios', 'sanciones', 'obligaciones', 'restrictivas', 'proteccionistas', 'reguladoras', 'normatividad', 'ordenanzas', 'autorizaciones', 'lineamientos', 'desregulaciones', 'obligatorias', 'requisitos', 'legales', 'normatividades', 'restrictivos'], 'alianzas': ['alianza', 'coaliciones', 'aliarse', 'pactos', 'liderazgos', 'vinculaciones', 'cooperaciones', 'relaciones', 'lealtades', 'sinergias', 'confrontaciones', 'estrategias', 'forjar', 'pactar', 'pacto', 'lazos', 'acuerdos', 'concertaciones', 'fundaciones', 'gobiernos', 'liderazgo', 'organizaciones', 'complicidades', 'pugnas', 'consolidar', 'consensos', 'aliados', 'lideres', 'conjuntas', 'disputas', 'ambiciones', 'contactos', 'contiendas', 'gobernantes', 'rivalidades', 'iniciativas', 'institucionales', 'pugna', 'luchas', 'acercamientos', 'asociaciones', 'estrategia', 'nexos', 'voluntades', 'independientes', 'empresariales', 'aliaron', 'clientelistas', 'uribistas', 'acercamiento'], 'reputación': ['prestigio', 'fama', 'notoriedad', 'popularidad', 'renombre', 'credibilidad', 'intachable', 'fortuna', 'celebridad', 'moralidad', 'merecida', 'gozaba', 'amistad', 'perspicacia', 'respetado', 'reputado', 'enemistad', 'moral', 'personalidad', 'honorabilidad', 'habilidad', 'calidad', 'reputada', 'respetable', 'admirada', 'honra', 'respetada', 'labrarse', 'influyente', 'solidez', 'sobrenombre', 'amistades', 'admirado', 'audacia', 'ciertamente', 'fructifera', 'honestidad', 'genio', 'indudablemente', 'apodo', 'honradez', 'experiencia', 'clientela', 'notablemente', 'talento', 'aprecio', 'rodearse', 'arruinar', 'pericia', 'profesionalidad']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLASIFICACIÓN SEGÚN CATEGORÍA DE LAS PALABRAS**\n",
        "\n",
        "Primeramente se identifica la cantidad de palabras según la categoría de la noticia con un conteó de frecuencias y se procede filtrar la información por titulo, url y texto."
      ],
      "metadata": {
        "id": "S7ApvG69sjN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_count_categorys=db_news.copy()\n",
        "data_count_categorys[['news_text_content']]=data_count_categorys[['news_text_content']].astype(str)\n",
        "data_count_categorys['news_url_text']=pd.DataFrame(textUrl)"
      ],
      "metadata": {
        "id": "TRfmWeQdhiok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_count_categorys2=data_count_categorys.copy()\n",
        "for i in diccionary:\n",
        "  exp_regular='\\\\b'+'(s)?(es)?\\\\b|\\\\b'.join(list(diccionary[i]))+'(s)?(es)?\\\\b'\n",
        "  nomColum1='count_'+i+'_title'\n",
        "  nomColum2='count_'+i+'_text'\n",
        "  nomColum3='count_'+i+'_url'\n",
        "\n",
        "  data_count_categorys2[nomColum1]=data_count_categorys2['news_title'].apply(lambda x: len(re.findall(exp_regular,x,re.IGNORECASE)))\n",
        "  data_count_categorys2[nomColum2]=data_count_categorys2['news_text_content'].apply(lambda x: len(re.findall(exp_regular,x,re.IGNORECASE)))\n",
        "  data_count_categorys2[nomColum3]=data_count_categorys2['news_url_text'].apply(lambda x: len(re.findall(exp_regular,x,re.IGNORECASE)))\n"
      ],
      "metadata": {
        "id": "SX_8A-qPkeaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas2 = ['news_id',\n",
        "       'count_macroeconomía_title', 'count_macroeconomía_text','count_macroeconomía_url',\n",
        "       'count_sostenibilidad_title','count_sostenibilidad_text','count_sostenibilidad_url',\n",
        "       'count_innovación_title', 'count_innovación_text', 'count_innovación_url',\n",
        "       'count_regulaciones_title','count_regulaciones_text','count_regulaciones_url',\n",
        "       'count_alianzas_title','count_alianzas_text', 'count_alianzas_url',\n",
        "       'count_reputación_title','count_reputación_text','count_reputación_url']"
      ],
      "metadata": {
        "id": "IPNQiAK1FQFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_count_categorys2[columnas2]"
      ],
      "metadata": {
        "id": "fEAz5_DZGvTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLASIFICACIÓN SEGÚN EL CLIENTE CORPORATIVO O SECTOR**\n",
        "\n",
        "Primero se realiza una eliminación de palaras que no son importantes en el nombre del cliente tales como: \"ssa\", \"s.a\", entre otros."
      ],
      "metadata": {
        "id": "UxdTOed5TQ8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_clients[\"nombre\"] = db_clients[\"nombre\"].apply(lambda x: re.sub(\"\\\\ssa\\\\b|\\\\sltda?\\\\b|\\\\ s a\\\\b|\\\\ sas\\\\b|\\\\ s.a.\\\\b|\\\\ 2 e p\\\\b|\\\\ ltda\\\\b|\\\\ c.i \\\\b|\\\\.\\\\b|\\\\ esp\\\\b\", \"\",x.lower()))\n",
        "db_clients[\"nombre\"] = db_clients[\"nombre\"].apply(lambda x: re.sub(r'[^\\w\\s]', \"\",x.lower()))"
      ],
      "metadata": {
        "id": "zH_wmg9p3EMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_result = pd.DataFrame()\n",
        "\n",
        "column_select = ['nit', 'news_id', 'news_url_absolute', 'news_init_date', \n",
        "    'news_final_date', 'news_title', 'count_name_tittle',\n",
        "    'count_name_text','count_name_url', 'count_sect_tittle', 'count_sect_text','count_sect_url','count_ciiu_tittle', 'count_ciiu_text','count_ciiu_url'\n",
        "       ]\n",
        "\n",
        "for j, i in enumerate(db_clients[\"nit\"]):\n",
        "    clie_news_filter = db_clients_news[db_clients_news[\"nit\"]==i][[\"news_id\", \"nit\"]]\n",
        "    data_filter = pd.merge(data_count_categorys, clie_news_filter, on= \"news_id\")\n",
        "    nombre = db_clients[db_clients[\"nit\"]==i][\"nombre\"].iloc[0]\n",
        "    sector = db_clients[db_clients[\"nit\"]==i][\"desc_ciiu_division\"].iloc[0]\n",
        "    ciiu = db_clients[db_clients[\"nit\"]==i][\"subsec\"].iloc[0]\n",
        "\n",
        "    data_filter[\"count_name_tittle\"] = data_filter[\"news_title\"].apply(lambda x: len(re.findall(nombre, x , re.IGNORECASE)))\n",
        "    data_filter[\"count_name_text\"] = data_filter[\"news_text_content\"].apply(lambda x: len(re.findall(nombre, x, re.IGNORECASE)))\n",
        "    data_filter[\"count_name_url\"] = data_filter[\"news_url_text\"].apply(lambda x: len(re.findall(nombre, x, re.IGNORECASE)))\n",
        "    data_filter[\"count_sect_tittle\"] = data_filter[\"news_title\"].apply(lambda x: len(re.findall(sector, x, re.IGNORECASE)))\n",
        "    data_filter[\"count_sect_text\"] = data_filter[\"news_text_content\"].apply(lambda x: len(re.findall(sector, x, re.IGNORECASE)))\n",
        "    data_filter[\"count_sect_url\"] = data_filter[\"news_url_text\"].apply(lambda x: len(re.findall(sector, x, re.IGNORECASE)))\n",
        "    data_filter[\"count_ciiu_tittle\"] = data_filter[\"news_title\"].apply(lambda x: len(re.findall(ciiu, x, re.IGNORECASE)))\n",
        "    data_filter[\"count_ciiu_text\"] = data_filter[\"news_text_content\"].apply(lambda x: len(re.findall(ciiu, x, re.IGNORECASE)))\n",
        "    data_filter[\"count_ciiu_url\"] = data_filter[\"news_url_text\"].apply(lambda x: len(re.findall(ciiu, x, re.IGNORECASE)))\n",
        "    \n",
        "    data_result = pd.concat([data_result,data_filter[column_select]], ignore_index=True)\n",
        "    print(\"Termine de contar el cliente:\" + str(i) + \" avance \" + str((j + 1)/len(db_clients[\"nit\"])))"
      ],
      "metadata": {
        "id": "HcPUjuaFwbBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_result2 = pd.merge(db_clients_news[[\"nit\", \"news_id\"]], data_count_categorys2[columnas2], on = \"news_id\", how = \"left\")\n",
        "data_result_final_aux = pd.merge(data_result, data_result2, on = [\"nit\", \"news_id\"])\n",
        "data_result_final = pd.merge(db_clients[[\"nit\", \"nombre\"]], data_result_final_aux, on = \"nit\")\n",
        "data_result_final.head()"
      ],
      "metadata": {
        "id": "gWQwREQT42DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_result_final"
      ],
      "metadata": {
        "id": "AKmA1u-Lq0Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nit=[]\n",
        "id_new=[]\n",
        "clasification=[]\n",
        "particip=[]\n",
        "for i in range(0, data_result_final.shape[0]):\n",
        "    id_new.append(data_result_final.news_id[i])\n",
        "    nit.append(data_result_final.nit[i])\n",
        "    sum_macroeconomia, sum_sostenibilidad, sum_innovacion, sum_regulacion, sum_alianzas,  sum_reputacion = 0, 0, 0, 0, 0, 0\n",
        "    count=[]\n",
        "    sum_macroeconomia=data_result_final.count_macroeconomía_text[i]+2*data_result_final.count_macroeconomía_title[i]+4*data_result_final.count_macroeconomía_url[i]          \n",
        "    sum_sostenibilidad=data_result_final.count_sostenibilidad_text[i]+2*data_result_final.count_sostenibilidad_title[i]+4*data_result_final.count_sostenibilidad_url[i]\n",
        "    sum_innovacion=data_result_final.count_innovación_text[i]+2*data_result_final.count_innovación_title[i]+4*data_result_final.count_innovación_url[i]\n",
        "    sum_regulacion=data_result_final.count_regulaciones_text[i]+2*data_result_final.count_regulaciones_title[i]+data_result_final.count_regulaciones_url[i]\n",
        "    sum_alianzas=data_result_final.count_alianzas_text[i]+2*data_result_final.count_alianzas_title[i]+4*data_result_final.count_alianzas_url[i]\n",
        "    sum_reputacion=data_result_final.count_reputación_text[i]+2*data_result_final.count_reputación_title[i]+4*data_result_final.count_reputación_url[i]\n",
        "    \n",
        "    count += [sum_macroeconomia, sum_sostenibilidad, sum_innovacion, sum_regulacion, sum_alianzas,  sum_reputacion]\n",
        "    max_value = max(count) \n",
        "    index=count.index(max_value)\n",
        "    \n",
        "    if max_value==0:\n",
        "      clasification.append('Descartable')\n",
        "    else:\n",
        "         if index==0:\n",
        "            clasification.append('macroeconomía')              \n",
        "         if index==1:\n",
        "            clasification.append('sostenibilidad')\n",
        "         if index==2:\n",
        "            clasification.append('innovacion')\n",
        "         if index==3:\n",
        "            clasification.append('regulaciones')\n",
        "         if index==4:\n",
        "            clasification.append('alianzas')\n",
        "         if index==5:\n",
        "            clasification.append('reputacion')\n",
        "\n",
        "    if data_result_final.count_name_tittle[i]>0 or data_result_final.count_name_text[i] >0 or data_result_final.count_name_url[i] >0 :       \n",
        "            particip.append('Cliente')\n",
        "    elif data_result_final.count_sect_tittle[i]>0 or data_result_final.count_sect_text[i] >0 or data_result_final.count_sect_url[i] >0 :       \n",
        "             particip.append('Sector') \n",
        "    elif data_result_final.count_ciiu_tittle[i]>0 or data_result_final.count_ciiu_text[i]>0 or data_result_final.count_ciiu_url[i] >0 :       \n",
        "             particip.append('Sector') \n",
        "    else:\n",
        "        particip.append('No Aplica')  \n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "r21GLR51WFcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clasificación**"
      ],
      "metadata": {
        "id": "8L9apelMEfiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_clasifier2 = pd.DataFrame()\n",
        "db_clasifier2['nit']=nit\n",
        "db_clasifier2['id_news']=id_new\n",
        "db_clasifier2['participation']=particip\n",
        "db_clasifier2['clasification']=clasification\n",
        "db_clasifier2"
      ],
      "metadata": {
        "id": "XUVLYIVmZvHq",
        "outputId": "acfc6b0b-41c3-4c9d-8ede-5a22fe89b423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             nit    id_news participation   clasification\n",
              "0      805027024  news12584     No Aplica      innovacion\n",
              "1      805027024  news12758     No Aplica    regulaciones\n",
              "2      805027024  news13241     No Aplica   macroeconomía\n",
              "3      805027024  news15048     No Aplica  sostenibilidad\n",
              "4      805027024  news15611     No Aplica      innovacion\n",
              "...          ...        ...           ...             ...\n",
              "74612  891102723  news99569     No Aplica        alianzas\n",
              "74613  891102723  news99573     No Aplica      innovacion\n",
              "74614  891102723  news99574     No Aplica      reputacion\n",
              "74615  891102723  news99576     No Aplica        alianzas\n",
              "74616  891102723  news99577     No Aplica  sostenibilidad\n",
              "\n",
              "[74617 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-136eaa06-7963-4a23-8b05-e6299d175475\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nit</th>\n",
              "      <th>id_news</th>\n",
              "      <th>participation</th>\n",
              "      <th>clasification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>805027024</td>\n",
              "      <td>news12584</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>innovacion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>805027024</td>\n",
              "      <td>news12758</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>regulaciones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>805027024</td>\n",
              "      <td>news13241</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>macroeconomía</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>805027024</td>\n",
              "      <td>news15048</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>sostenibilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>805027024</td>\n",
              "      <td>news15611</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>innovacion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74612</th>\n",
              "      <td>891102723</td>\n",
              "      <td>news99569</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>alianzas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74613</th>\n",
              "      <td>891102723</td>\n",
              "      <td>news99573</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>innovacion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74614</th>\n",
              "      <td>891102723</td>\n",
              "      <td>news99574</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>reputacion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74615</th>\n",
              "      <td>891102723</td>\n",
              "      <td>news99576</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>alianzas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74616</th>\n",
              "      <td>891102723</td>\n",
              "      <td>news99577</td>\n",
              "      <td>No Aplica</td>\n",
              "      <td>sostenibilidad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74617 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-136eaa06-7963-4a23-8b05-e6299d175475')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-136eaa06-7963-4a23-8b05-e6299d175475 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-136eaa06-7963-4a23-8b05-e6299d175475');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##limpieza, tomado de: https://github.com/institutohumai/cursos-python/tree/master/NLP/3_Embeddings\n"
      ],
      "metadata": {
        "id": "NRorqO-kC86c"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}